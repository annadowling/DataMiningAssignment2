{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - RandomForest - Major Occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries Imported\n",
      "['Masters' 'Some_College' 'College' 'High_School' 'Professional' 'Grammar'\n",
      " 'Special' 'Doctoral' 'Other']\n"
     ]
    }
   ],
   "source": [
    "# Import feature subset with Major_Occupation Column and one hot encoded values\n",
    "\n",
    "#Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "print('Libraries Imported')\n",
    "\n",
    "originalDF = pd.read_csv('educationFeatureSubset.csv')\n",
    "\n",
    "# Next we check the Education_Attainment options in the dataset for use with classification\n",
    "print(originalDF.Education_Attainment.unique())\n",
    "\n",
    "# Now we replace those values with integers for use with the classification algorithm\n",
    "education_values = {\"Education_Attainment\": {\"Masters\": 1, \"Some_College\": 2, \"College\": 3, \"High_School\": 4, \"Professional\": 5, \"Grammar\": 6, \"Special\": 7, \"Doctoral\": 8, \"Other\": 9}}\n",
    "originalDF.replace(education_values, inplace=True)\n",
    "\n",
    "featureDF = originalDF[originalDF.columns.difference(['Education_Attainment'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With knn, you can determine membership probabilities for each of the 3 labels. As you can see, the predict() function just picks the most likely label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "3    2\n",
      "4    3\n",
      "Name: Education_Attainment, dtype: int64\n",
      "Int64Index([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "#Creating the dependent variable class\n",
    "factor = pd.factorize(originalDF['Education_Attainment'])\n",
    "originalDF['Education_Attainment'] = factor[0]\n",
    "definitions = factor[1]\n",
    "print(originalDF['Education_Attainment'].head())\n",
    "print(definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into independent and dependent variables\n",
    "X, y = featureDF, originalDF['Education_Attainment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Training and Test set from data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annadowling/miniconda3/envs/py3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/annadowling/miniconda3/envs/py3/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Users/annadowling/miniconda3/envs/py3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Random Forest Classification to the Training set\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Education    1    2    3   4  5   6   7  8  9\n",
      "Actual Education                                       \n",
      "1                     96   91  133  14  7   0   4  2  1\n",
      "2                     91  409  209  72  5   2  20  5  2\n",
      "3                    143  268  248  28  5   1   7  9  1\n",
      "4                     22  141   60  62  4  12   7  0  2\n",
      "5                     24   27   17   2  0   0   2  1  0\n",
      "6                      1    3    0  18  0  15   1  0  1\n",
      "7                     10   54   28  10  2   0   0  1  0\n",
      "8                     23   22   18   0  1   1   3  6  1\n",
      "9                      8   18   11  11  0   3   0  0  1\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "#Reverse factorize (converting y_pred from 0s,1s and 2s to 1,2,3,4,5,6,7,8,9\n",
    "reversefactor = dict(zip(range(9),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pred = np.vectorize(reversefactor.get)(y_pred)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['Actual Education'], colnames=['Predicted Education']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Age', 0.2822004856671727), ('Gender', 0.037285420765616084), ('Major_Geographical_Location', 0.03274798761222546), ('Marital_Status', 0.06610209116297065), ('Opinions_on_Censorship', 0.07781155773034668), ('Race', 0.03481496588414419), ('Registered_to_Vote', 0.0375239408098407), ('Sexual_Preference', 0.03891591424235831), ('Unnamed: 0', 0.2861679403503963), ('Web_Ordering', 0.03473139029766987), ('Years_on_Internet', 0.07169830547725906)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['randomForest/randomforestmodelEA.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(zip(featureDF, classifier.feature_importances_)))\n",
    "joblib.dump(classifier, 'randomForest/randomforestmodelEA.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annadowling/miniconda3/envs/py3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Now we should split our data into a training set and a test set in order to properly assess our model using PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.45453297, -0.33385824],\n",
       "       [-0.2606989 ,  0.10065705],\n",
       "       [-0.41473897,  0.1155537 ],\n",
       "       [-0.40843431,  0.12486152],\n",
       "       [ 0.53108298, -0.38371677]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_model = PCA(n_components=2)\n",
    "pca_model.fit(X_train)\n",
    "X_train = pca_model.transform(X_train)\n",
    "X_test = pca_model.transform(X_test)\n",
    "\n",
    "# 2-Dimensions\n",
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Random Forest Classification to the Training set\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Education    1    2    3   4  5  6   7   8  9\n",
      "Actual Education                                       \n",
      "1                     67  121  120  18  9  0   8   6  1\n",
      "2                    114  355  226  91  5  5  18   8  7\n",
      "3                    124  278  224  51  7  2  16  13  8\n",
      "4                     41  138   54  47  2  4   5   2  4\n",
      "5                     13   28   18   8  1  0   2   1  0\n",
      "6                      4   23    8   9  1  3   0   0  0\n",
      "7                     13   57   31   8  0  0   2   5  1\n",
      "8                     14   20   25   1  0  0   1   3  0\n",
      "9                      4   15    4   3  0  0   1   1  0\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "#Reverse factorize (converting y_pred from 0s,1s and 2s to 1,2,3,4,5,6,7,8,9\n",
    "reversefactor = dict(zip(range(9),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pred = np.vectorize(reversefactor.get)(y_pred)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['Actual Education'], colnames=['Predicted Education']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Age', 0.4988679768829341), ('Gender', 0.5011320231170657)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['randomForest/randomforestmodelEAPCA.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(zip(featureDF, classifier.feature_importances_)))\n",
    "joblib.dump(classifier, 'randomForest/randomforestmodelEAPCA.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
