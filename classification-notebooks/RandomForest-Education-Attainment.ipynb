{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - RandomForest - Major Occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries Imported\n",
      "['Masters' 'Some_College' 'College' 'High_School' 'Professional' 'Grammar'\n",
      " 'Special' 'Doctoral' 'Other']\n"
     ]
    }
   ],
   "source": [
    "# Import feature subset with Major_Occupation Column and one hot encoded values\n",
    "\n",
    "#Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "print('Libraries Imported')\n",
    "\n",
    "originalDF = pd.read_csv('educationFeatureSubset.csv')\n",
    "dfOHE = pd.read_csv('oheTransformedData.csv')\n",
    "dfOHE['Education_Attainment'] = pd.Series(originalDF['Education_Attainment'], index=dfOHE.index)\n",
    "dfOHE.fillna(0, inplace=True)\n",
    "\n",
    "# Next we check the Education_Attainment options in the dataset for use with classification\n",
    "print(dfOHE.Education_Attainment.unique())\n",
    "\n",
    "# Now we replace those values with integers for use with the classification algorithm\n",
    "education_values = {\"Education_Attainment\": {\"Masters\": 1, \"Some_College\": 2, \"College\": 3, \"High_School\": 4, \"Professional\": 5, \"Grammar\": 6, \"Special\": 7, \"Doctoral\": 8, \"Other\": 9}}\n",
    "dfOHE.replace(education_values, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With knn, you can determine membership probabilities for each of the 3 labels. As you can see, the predict() function just picks the most likely label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "3    2\n",
      "4    3\n",
      "Name: Education_Attainment, dtype: int64\n",
      "Int64Index([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "#Creating the dependent variable class\n",
    "factor = pd.factorize(dfOHE['Education_Attainment'])\n",
    "dfOHE['Education_Attainment'] = factor[0]\n",
    "definitions = factor[1]\n",
    "print(dfOHE['Education_Attainment'].head())\n",
    "print(definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into independent and dependent variables\n",
    "X, y = dfOHE.loc[:, dfOHE.columns != 'Education_Attainment'], dfOHE['Education_Attainment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Training and Test set from data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Random Forest Classification to the Training set\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Education   1    2    3   4  5   6  7  8  9\n",
      "Actual Education                                     \n",
      "1                    57  101  177   7  1   0  2  2  1\n",
      "2                    42  433  264  63  4   1  4  2  2\n",
      "3                    84  264  330  22  2   0  4  2  2\n",
      "4                    18  145   75  59  0   9  4  0  0\n",
      "5                    10   26   33   3  0   0  1  0  0\n",
      "6                     0    1    2  22  0  13  0  0  1\n",
      "7                     6   53   42   3  0   0  1  0  0\n",
      "8                    26   16   27   3  0   0  1  2  0\n",
      "9                     3   15   15   8  0   7  3  1  0\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "#Reverse factorize (converting y_pred from 0s,1s and 2s to 1,2,3,4,5,6,7,8,9\n",
    "reversefactor = dict(zip(range(9),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pred = np.vectorize(reversefactor.get)(y_pred)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['Actual Education'], colnames=['Predicted Education']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Years_on_Internet-0', 0.014567759034696922), ('Years_on_Internet-1', 0.025131556807920195), ('Years_on_Internet-2', 0.027618413797265873), ('Years_on_Internet-3', 0.0247338192019051), ('Years_on_Internet-4', 0.027087008892898622), ('Web_Ordering-0', 0.004726127384921387), ('Web_Ordering-1', 0.014156521116047021), ('Web_Ordering-2', 0.011821728769800647), ('Not_Purchasing_Privacy', 0.0), ('Not_Purchasing_Prefer_people', 0.0), ('Not_Purchasing_Too_complicated', 0.0), ('Not_Purchasing_Easier_locally', 0.0), ('Not_Purchasing_Security', 0.0), ('Age', 0.8501570649945442)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['randomForest/randomforestmodelEA.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(zip(dfOHE, classifier.feature_importances_)))\n",
    "joblib.dump(classifier, 'randomForest/randomforestmodelEA.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Now we should split our data into a training set and a test set in order to properly assess our model using PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.35529674, -0.5327504 ],\n",
       "       [-0.1912675 , -0.47005044],\n",
       "       [-0.52157889, -0.55681204],\n",
       "       [-0.54437412,  0.61908668],\n",
       "       [ 0.80611043,  0.82767697]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_model = PCA(n_components=2)\n",
    "pca_model.fit(X_train)\n",
    "X_train = pca_model.transform(X_train)\n",
    "X_test = pca_model.transform(X_test)\n",
    "\n",
    "# 2-Dimensions\n",
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Random Forest Classification to the Training set\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Education   1    2    3   4  5   6  7  8  9\n",
      "Actual Education                                     \n",
      "1                    52   87  198   5  3   0  1  4  0\n",
      "2                    29  471  276  43  2   1  5  2  0\n",
      "3                    61  234  398  16  3   0  1  8  2\n",
      "4                     8  151   73  48  0  16  0  0  1\n",
      "5                     6   31   32   0  1   0  0  1  0\n",
      "6                     1    7    5  14  0  21  0  0  0\n",
      "7                     2   72   35   6  1   0  1  0  0\n",
      "8                    11   17   28   2  1   1  1  3  0\n",
      "9                     2    8   10   3  0   2  2  1  0\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "#Reverse factorize (converting y_pred from 0s,1s and 2s to 1,2,3,4,5,6,7,8,9\n",
    "reversefactor = dict(zip(range(9),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pred = np.vectorize(reversefactor.get)(y_pred)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['Actual Education'], colnames=['Predicted Education']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Years_on_Internet-0', 0.5138969388324922), ('Years_on_Internet-1', 0.4861030611675078)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['randomForest/randomforestmodelEAPCA.pkl']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(zip(dfOHE, classifier.feature_importances_)))\n",
    "joblib.dump(classifier, 'randomForest/randomforestmodelEAPCA.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
