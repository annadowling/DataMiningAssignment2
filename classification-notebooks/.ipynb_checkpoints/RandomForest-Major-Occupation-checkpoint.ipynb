{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - RandomForest - Major Occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries Imported\n",
      "['Professional' 'Education' 'Computer' 'Other' 'Management']\n"
     ]
    }
   ],
   "source": [
    "# Import feature subset with Major_Occupation Column and one hot encoded values\n",
    "\n",
    "#Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "print('Libraries Imported')\n",
    "\n",
    "originalDF = pd.read_csv('occupationFeatureSubset.csv')\n",
    "\n",
    "# Next we check the Major_Occupation options in the dataset for use with classification\n",
    "print(originalDF.Major_Occupation.unique())\n",
    "\n",
    "# Now we replace those values with integers for use with the classification algorithm\n",
    "occupation_values = {\"Major_Occupation\": {\"Professional\": 1, \"Education\": 2, \"Computer\": 3, \"Other\": 4, \"Management\": 5}}\n",
    "originalDF.replace(occupation_values, inplace=True)\n",
    "\n",
    "featureDF = originalDF[originalDF.columns.difference(['Education_Attainment'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "3    0\n",
      "4    1\n",
      "Name: Major_Occupation, dtype: int64\n",
      "Int64Index([1, 2, 3, 4, 5], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "#Creating the dependent variable class\n",
    "factor = pd.factorize(originalDF['Major_Occupation'])\n",
    "originalDF['Major_Occupation'] = factor[0]\n",
    "definitions = factor[1]\n",
    "print(originalDF['Major_Occupation'].head())\n",
    "print(definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into independent and dependent variables\n",
    "X, y = featureDF, originalDF['Major_Occupation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Training and Test set from data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annadowling/miniconda3/envs/py3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/annadowling/miniconda3/envs/py3/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Users/annadowling/miniconda3/envs/py3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Random Forest Classification to the Training set\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Occupations    1    2    3    4    5\n",
      "Actual Occupations                            \n",
      "1                      551    1    0    0    0\n",
      "2                        2  606    0    0    0\n",
      "3                        0    2  508    1    0\n",
      "4                        0    0    1  570    0\n",
      "5                        0    0    0    1  284\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "#Reverse factorize (converting y_pred from 0s,1s and 2s to 1,2,3,4,5 \n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pred = np.vectorize(reversefactor.get)(y_pred)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['Actual Occupations'], colnames=['Predicted Occupations']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Age', 0.08948121928054076), ('Gender', 0.006496663244159874), ('Major_Geographical_Location', 0.008822070335960993), ('Major_Occupation', 0.7637849073833881), ('Marital_Status', 0.030925637248429207), ('Opinions_on_Censorship', 0.010020164124644263), ('Race', 0.0059264698315498136), ('Registered_to_Vote', 0.006791925422551544), ('Sexual_Preference', 0.006751874504437737), ('Unnamed: 0', 0.03273216996222705), ('Web_Ordering', 0.007572573741081656), ('Years_on_Internet', 0.030694324921028925)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['randomForest/randomforestmodelMO.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(zip(featureDF, classifier.feature_importances_)))\n",
    "joblib.dump(classifier, 'randomForest/randomforestmodelMO.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annadowling/miniconda3/envs/py3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Now we should split our data into a training set and a test set in order to properly assess our model using PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.45800606, -0.3818205 ],\n",
       "       [-0.27939691, -0.30053969],\n",
       "       [-0.4158031 ,  0.10002422],\n",
       "       [-0.39586984,  0.26129094],\n",
       "       [ 0.54280963, -0.16812243]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_model = PCA(n_components=2)\n",
    "pca_model.fit(X_train)\n",
    "X_train = pca_model.transform(X_train)\n",
    "X_test = pca_model.transform(X_test)\n",
    "\n",
    "# 2-Dimensions\n",
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Random Forest Classification to the Training set\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Occupations    1    2    3    4    5\n",
      "Actual Occupations                            \n",
      "1                      287  108   81   60   29\n",
      "2                      111  322   71   54   14\n",
      "3                      108   86  239   65   27\n",
      "4                       63   64   86  301   60\n",
      "5                       29   29   41   81  111\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "#Reverse factorize (converting y_pred from 0s,1s and 2s to 1,2,3,4,5,6,7,8,9\n",
    "reversefactor = dict(zip(range(9),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pred = np.vectorize(reversefactor.get)(y_pred)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['Actual Occupations'], colnames=['Predicted Occupations']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Age', 0.4982645549775929), ('Gender', 0.5017354450224071)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['randomForest/randomforestmodelMOPCA.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(zip(featureDF, classifier.feature_importances_)))\n",
    "joblib.dump(classifier, 'randomForest/randomforestmodelMOPCA.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
