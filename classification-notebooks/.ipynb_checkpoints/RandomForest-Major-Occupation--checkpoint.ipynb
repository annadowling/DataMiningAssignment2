{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - RandomForest - Major Occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries Imported\n",
      "['Professional' 'Education' 'Computer' 'Other' 'Management']\n"
     ]
    }
   ],
   "source": [
    "# Import feature subset with Major_Occupation Column and one hot encoded values\n",
    "\n",
    "#Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "print('Libraries Imported')\n",
    "\n",
    "originalDF = pd.read_csv('occupationFeatureSubset.csv')\n",
    "dfOHE = pd.read_csv('oheTransformedData.csv')\n",
    "dfOHE['Major_Occupation'] = pd.Series(originalDF['Major_Occupation'], index=dfOHE.index)\n",
    "dfOHE.fillna(0, inplace=True)\n",
    "\n",
    "# Next we check the Major_Occupation options in the dataset for use with classification\n",
    "print(dfOHE.Major_Occupation.unique())\n",
    "\n",
    "# Now we replace those values with integers for use with the classification algorithm\n",
    "occupation_values = {\"Major_Occupation\": {\"Professional\": 1, \"Education\": 2, \"Computer\": 3, \"Other\": 4, \"Management\": 5}}\n",
    "dfOHE.replace(occupation_values, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "3    0\n",
      "4    1\n",
      "Name: Major_Occupation, dtype: int64\n",
      "Int64Index([1, 2, 3, 4, 5], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "#Creating the dependent variable class\n",
    "factor = pd.factorize(dfOHE['Major_Occupation'])\n",
    "dfOHE['Major_Occupation'] = factor[0]\n",
    "definitions = factor[1]\n",
    "print(dfOHE['Major_Occupation'].head())\n",
    "print(definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into independent and dependent variables\n",
    "X, y = dfOHE.loc[:, dfOHE.columns != 'Major_Occupation'], dfOHE['Major_Occupation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Training and Test set from data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annadowling/miniconda3/envs/py3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/annadowling/miniconda3/envs/py3/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Users/annadowling/miniconda3/envs/py3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Random Forest Classification to the Training set\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Occupations    1    2    3    4   5\n",
      "Actual Occupations                           \n",
      "1                      134   62  139  140  77\n",
      "2                       92  339   83   65  29\n",
      "3                      118   89  187   62  55\n",
      "4                      141   60   72  238  60\n",
      "5                       75   36   65   71  38\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "#Reverse factorize (converting y_pred from 0s,1s and 2s to 1,2,3,4,5 \n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pred = np.vectorize(reversefactor.get)(y_pred)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['Actual Occupations'], colnames=['Predicted Occupations']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Web_Ordering-0', 0.0017708664758203211), ('Web_Ordering-1', 0.014839329020990643), ('Web_Ordering-2', 0.014860594761882376), ('Years_on_Internet-0', 0.01357686226110848), ('Years_on_Internet-1', 0.017251934149581406), ('Years_on_Internet-2', 0.01959310753255228), ('Years_on_Internet-3', 0.0126640954663845), ('Years_on_Internet-4', 0.023177654198224363), ('Race-0', 0.0059902339435350714), ('Race-1', 0.0061413963710338), ('Race-2', 0.004829092635623404), ('Race-3', 0.0017739407327096522), ('Race-4', 0.0029885356216903048), ('Race-5', 0.0053559028694415405), ('Race-6', 0.007652743643874823), ('Race-7', 0.018139215576776967), ('Marital_Status-0', 0.011652871882658572), ('Marital_Status-1', 0.021898035090357298), ('Marital_Status-2', 0.004361058670094184), ('Marital_Status-3', 0.011854281492766187), ('Marital_Status-4', 0.0046197868328403955), ('Marital_Status-5', 0.03029796765260575), ('Marital_Status-6', 0.004908147990376041), ('Sexual_Preference-0', 0.007851921909903494), ('Sexual_Preference-1', 0.009393496158604565), ('Sexual_Preference-2', 0.018251308081605796), ('Sexual_Preference-3', 0.002986025889483901), ('Sexual_Preference-4', 0.012338062179961001), ('Sexual_Preference-5', 0.0009048269636171668), ('Registered_to_Vote-0', 0.011198207966148203), ('Registered_to_Vote-1', 0.008164248189470553), ('Registered_to_Vote-2', 0.00572386816859456), ('Registered_to_Vote-3', 0.01449090752165512), ('Major_Geographical_Location-0', 0.001365562417013283), ('Major_Geographical_Location-1', 0.0029083794489919886), ('Major_Geographical_Location-2', 0.009375095911577263), ('Major_Geographical_Location-3', 0.00031377996505122457), ('Major_Geographical_Location-4', 0.0094488692777335), ('Major_Geographical_Location-5', 0.0006954777439795526), ('Major_Geographical_Location-6', 0.006831327063871362), ('Major_Geographical_Location-7', 0.0008177380443820798), ('Major_Geographical_Location-8', 0.01659472686668565), ('Major_Geographical_Location-9', 0.0003073774138976363), ('Gender-0', 0.015356599494672035), ('Gender-1', 0.015488199592161005), ('Age', 0.46186816389807017), ('Opinions_on_Censorship', 0.10712817495994056)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['randomForest/randomforestmodelMO.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(zip(dfOHE, classifier.feature_importances_)))\n",
    "joblib.dump(classifier, 'randomForest/randomforestmodelMO.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annadowling/miniconda3/envs/py3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Now we should split our data into a training set and a test set in order to properly assess our model using PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.7699573 , -0.52624244],\n",
       "       [-0.48446553,  0.00212533],\n",
       "       [-0.88943286, -0.10226339],\n",
       "       [-0.80950549, -0.45917265],\n",
       "       [ 1.05641303, -0.6577288 ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_model = PCA(n_components=2)\n",
    "pca_model.fit(X_train)\n",
    "X_train = pca_model.transform(X_train)\n",
    "X_test = pca_model.transform(X_test)\n",
    "\n",
    "# 2-Dimensions\n",
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Random Forest Classification to the Training set\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Occupations    1    2    3    4   5\n",
      "Actual Occupations                           \n",
      "1                      161   84  135  121  64\n",
      "2                       82  299   83   86  22\n",
      "3                      120  112  184   62  47\n",
      "4                      145   69   73  217  70\n",
      "5                       81   39   68   70  33\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "#Reverse factorize (converting y_pred from 0s,1s and 2s to 1,2,3,4,5,6,7,8,9\n",
    "reversefactor = dict(zip(range(9),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pred = np.vectorize(reversefactor.get)(y_pred)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['Actual Occupations'], colnames=['Predicted Occupations']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Web_Ordering-0', 0.5071124486335268), ('Web_Ordering-1', 0.4928875513664733)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['randomForest/randomforestmodelMOPCA.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(zip(dfOHE, classifier.feature_importances_)))\n",
    "joblib.dump(classifier, 'randomForest/randomforestmodelMOPCA.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
